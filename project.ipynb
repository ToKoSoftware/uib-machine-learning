{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Implementation of a decision tree classifier\n",
    "\n",
    "Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d0bb63a0844f49a"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-21T16:26:37.136137Z",
     "start_time": "2023-09-21T16:26:37.123298Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "\n",
    "from src.calculations import find_best_split\n",
    "from src.tree_node import TreeNode\n",
    "from src.util import tree_to_json"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "14939e50711de451"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learning Algorithm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3146ab66afd64771"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "    Recursively implemented algorithm for \"learning\" / creating a decision tree\n",
    "\n",
    "    Parameters:\n",
    "    X (2D Array): Feature matrix\n",
    "    y (Array): Class labels\n",
    "    impurity_measure (String): Type of impurity measure to use ('gini' / 'entropy')\n",
    "    prune (bool, optional): True or false regarding the question to prune the tree. By default False is set.\n",
    "    prune_data (tuple, optional): Validation data for pruning. By default None is set.\n",
    "\n",
    "    Return:\n",
    "    Root node of the decision tree (Type: TreeNode)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def learn(X, y, impurity_measure, prune=False, prune_data=None):\n",
    "    # If all labels in the current node are the same (pure node)\n",
    "    if len(np.unique(y)) == 1:\n",
    "        # Returning leaf node with the class label\n",
    "        leaf = TreeNode()\n",
    "        leaf.label = y[0]\n",
    "        return leaf\n",
    "    # if all features have the same value\n",
    "    if np.all(X[:, 0] == X[:, 0][0]):\n",
    "        # Returning leaf node with the class label being the most frequent class in the current node.\n",
    "        leaf = TreeNode()\n",
    "        leaf.label = Counter(y).most_common(1)[0][0]\n",
    "        return leaf\n",
    "    # If not stopped, Calculating best split for decision tree based on information gain\n",
    "    best_feature_index, best_threshold = find_best_split(X, y, impurity_measure)\n",
    "\n",
    "    if best_feature_index is None:\n",
    "        leaf = TreeNode()\n",
    "        leaf.label = Counter(y).most_common(1)[0][0]\n",
    "        return leaf\n",
    "    # Creating tree node on the basis of calculated best feature and threshold\n",
    "    node = TreeNode()\n",
    "    node.feature_index = best_feature_index\n",
    "    node.threshold = best_threshold\n",
    "    # Splitting data in left and right subtree\n",
    "    left_mask = X[:, best_feature_index] <= best_threshold\n",
    "    right_mask = ~left_mask\n",
    "    # Recursive call of functions for left and right subtrees for creating child nodes\n",
    "    node.left = learn(X[left_mask], y[left_mask], impurity_measure, prune, prune_data)\n",
    "    node.right = learn(\n",
    "        X[right_mask], y[right_mask], impurity_measure, prune, prune_data\n",
    "    )\n",
    "    # When pruning is enabled\n",
    "    if prune:\n",
    "        # Comparing accuracy of node before pruning\n",
    "        majority_class = Counter(y).most_common(1)[0][0]\n",
    "        accuracy_before_prune = np.mean(predict(X, node) == y)\n",
    "\n",
    "        node_label = node.label if node.label is not None else majority_class\n",
    "        # Comparing accuracy of node after pruning\n",
    "        node_accuracy = np.mean(predict(prune_data[0], node) == prune_data[1])\n",
    "        #  If pruning improves accuracy or maintains the same accuracy, the node is pruned\n",
    "        if node_accuracy >= accuracy_before_prune:\n",
    "            #  Making it like a leaf note\n",
    "            node.left = None\n",
    "            node.right = None\n",
    "            node.label = node_label\n",
    "    # returns the constructed tree with the root node (-> which recursively defines the decision tree)\n",
    "    return node"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T16:26:37.156150Z",
     "start_time": "2023-09-21T16:26:37.135859Z"
    }
   },
   "id": "b8f6109b0e4065a7"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Predicting the class label for a single sample using the decision tree.\n",
    "    The decision tree is recursively traversated, until leaf node is reached.\n",
    "    Parameters:\n",
    "    node (TreeNode): Current node in the decision tree.\n",
    "    x (Array): Feature values for a single sample.\n",
    "\n",
    "    Return:\n",
    "    Predicted class label (Type: float)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def predict_single(node, x):\n",
    "    # When leaf node is reached\n",
    "    if node.label is not None:\n",
    "        # Return class label\n",
    "        return node.label\n",
    "    # Recursive Traversation of tree based on feature value in comparison with the threshold of the node\n",
    "    if x[node.feature_index] <= node.threshold:\n",
    "        return predict_single(node.left, x)\n",
    "    else:\n",
    "        return predict_single(node.right, x)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Predicting  class labels for multiple samples using the decision tree.\n",
    "\n",
    "    Parameters:\n",
    "    X (2D Array): Feature matrix for multiple samples.\n",
    "    tree (TreeNode): Root node of the decision tree.\n",
    "\n",
    "    Return:\n",
    "    Predicted class labels for the input samples (Type: Array)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def predict(X, tree):\n",
    "    # Recursive Traversation of tree till leaf is reached and return of array of predicted class labels\n",
    "    return np.array([predict_single(tree, x) for x in X])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T16:26:37.156636Z",
     "start_time": "2023-09-21T16:26:37.142652Z"
    }
   },
   "id": "b02d7d155d72ae86"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Decision Tree:\n",
      "Accuracy: 0.875\n",
      "Time: 1.101304054260254\n",
      "\n",
      "Scikit-Learn Decision Tree:\n",
      "Accuracy: 0.8729166666666667\n",
      "Time: 0.003976106643676758\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "wine_data = pd.read_csv(\"./data/wine_dataset.csv\")\n",
    "# X = wine_data[['citric acid', 'residual sugar', 'pH', 'sulphates', 'alcohol']].values\n",
    "X = wine_data.iloc[:, :-1].values\n",
    "# y = wine_data['type'].values\n",
    "y = wine_data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Train and evaluate our custom decision tree (entropy with pruning)\n",
    "start_time = time.time()\n",
    "# tree_custom = learn(X_train, y_train, impurity_measure='gini', prune=True, prune_data=(X_val, y_val))\n",
    "# tree_custom = learn(X_train, y_train, impurity_measure='gini', prune=False, prune_data=None)\n",
    "tree_custom = learn(\n",
    "    X_train, y_train, impurity_measure=\"entropy\", prune=True, prune_data=(X_val, y_val)\n",
    ")\n",
    "# tree_custom = learn(X_train, y_train, impurity_measure='entropy', prune=False, prune_data=None)\n",
    "y_val_pred_custom = predict(X_val, tree_custom)\n",
    "custom_accuracy = accuracy_score(y_val, y_val_pred_custom)\n",
    "custom_time = time.time() - start_time\n",
    "\n",
    "# Train and evaluate scikit-learn's DecisionTreeClassifier\n",
    "start_time = time.time()\n",
    "tree_sklearn = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
    "tree_sklearn.fit(X_train, y_train)\n",
    "y_val_pred_sklearn = tree_sklearn.predict(X_val)\n",
    "# Accuracy calculation realized by percentage-wise match of input arrays\n",
    "sklearn_accuracy = accuracy_score(y_val, y_val_pred_sklearn)\n",
    "sklearn_time = time.time() - start_time\n",
    "\n",
    "# Print the results\n",
    "print(\"Custom Decision Tree:\")\n",
    "print(\"Accuracy:\", custom_accuracy)\n",
    "print(\"Time:\", custom_time)\n",
    "\n",
    "print(\"\\nScikit-Learn Decision Tree:\")\n",
    "print(\"Accuracy:\", sklearn_accuracy)\n",
    "print(\"Time:\", sklearn_time)\n",
    "\n",
    "\n",
    "# Retrieve feature names from the dataset\n",
    "# feature_names = wine_data[['citric acid', 'residual sugar', 'pH', 'sulphates', 'alcohol']].columns.tolist()\n",
    "feature_names = wine_data.columns[:-1].tolist()\n",
    "\n",
    "# Visualize the custom decision tree as JSON\n",
    "custom_tree_json = tree_to_json(tree_custom, feature_names)\n",
    "# print(\"Custom Decision Tree (JSON format):\")\n",
    "# print(custom_tree_json)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T16:26:38.268813Z",
     "start_time": "2023-09-21T16:26:37.154303Z"
    }
   },
   "id": "23e528af91a25367"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
