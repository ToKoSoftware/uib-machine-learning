{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Implementation of Decision Tree Algorithm\n",
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bb8fa2958d60515"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from src.util import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:47:44.449037Z",
     "start_time": "2023-09-17T13:47:44.392029Z"
    }
   },
   "id": "5f40249a475e1071"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample data "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cea3f89f5f5fb004"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/wine_dataset.csv')\n",
    "y = X['type']\n",
    "# remove column type from X\n",
    "X = X.drop('type', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:47:44.467365Z",
     "start_time": "2023-09-17T13:47:44.401647Z"
    }
   },
   "id": "96e37069cfe152ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "daaafe18cd35f9dd"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:47:44.469833Z",
     "start_time": "2023-09-17T13:47:44.411717Z"
    }
   },
   "outputs": [],
   "source": [
    "def learn(X, y, impurity_measure='entropy'):\n",
    "    # check if the impurity_measure is valid\n",
    "    if impurity_measure not in ['entropy', 'gini']:\n",
    "        raise ValueError('impurity_measure must be either \"entropy\" or \"gini\"')\n",
    "    # check if the data is valid\n",
    "    if len(X) != len(y):\n",
    "        raise ValueError('X and y must have the same length')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "# check if data is pure, meaning that all samples belong to the same class\n",
    "def check_purity(y):\n",
    "    # create a distinct list of classes\n",
    "    unique_classes = np.unique(y)\n",
    "    # check if there is only one class in the list\n",
    "    return len(unique_classes) == 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:47:44.469996Z",
     "start_time": "2023-09-17T13:47:44.418601Z"
    }
   },
   "id": "9bc924946f8233f0"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "def classify_data(y):\n",
    "    # create a distinct list of classes and their counts\n",
    "    unique_classes, counts_unique_classes = np.unique(y, return_counts=True)\n",
    "    # get the index of the most frequent class\n",
    "    index = counts_unique_classes.argmax()\n",
    "    # return the most frequent class\n",
    "    classification = unique_classes[index]\n",
    "    return classification"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:47:44.470851Z",
     "start_time": "2023-09-17T13:47:44.425504Z"
    }
   },
   "id": "8c4e74f09f5518be"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "def get_potential_splits(X):\n",
    "    potential_splits = {}\n",
    "    # get the number of rows and columns\n",
    "    _, n_columns = X.shape\n",
    "    # iterate over each column to get the potential splits\n",
    "    for column_index in range(n_columns):\n",
    "        # get the values of the column\n",
    "        values = X[:, column_index]\n",
    "        # get the distinct values of the column because this the information is higher\n",
    "        unique_values = np.unique(values)\n",
    "\n",
    "        for index in range(len(unique_values)):\n",
    "            if index != 0:\n",
    "                current_value = unique_values[index]\n",
    "                previous_value = unique_values[index - 1]\n",
    "                # calculate the potential split -> calculate the average between the current and previous value\n",
    "                potential_split = (current_value + previous_value) / 2\n",
    "                # if no array exists for the current column, create one\n",
    "                if column_index not in potential_splits:\n",
    "                    potential_splits[column_index] = []\n",
    "                potential_splits[column_index].append(potential_split)\n",
    "    return potential_splits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:47:44.472352Z",
     "start_time": "2023-09-17T13:47:44.433865Z"
    }
   },
   "id": "412d8efbdd143521"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "def split_data(X, y, split_column, split_value):\n",
    "    # get the values of the column\n",
    "    split_column_values = X[:, split_column]\n",
    "    # get the indices of the rows that are less than the split value\n",
    "    less_than_split_value = np.where(split_column_values <= split_value)[0]\n",
    "    # get the indices of the rows that are greater than the split value\n",
    "    greater_than_split_value = np.where(split_column_values > split_value)[0]\n",
    "    # split the data\n",
    "    X_less_than = X[less_than_split_value]\n",
    "    y_less_than = y[less_than_split_value]\n",
    "    X_greater_than = X[greater_than_split_value]\n",
    "    y_greater_than = y[greater_than_split_value]\n",
    "    return X_less_than, y_less_than, X_greater_than, y_greater_than"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:47:44.472759Z",
     "start_time": "2023-09-17T13:47:44.439707Z"
    }
   },
   "id": "d4ef06ad66de7d88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Entropy\n",
    "\n",
    "Measurement of the tendency to differ to the same class. The lower the entropy, the more pure the data is."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6db127981f300e4"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def calculate_entropy(y):\n",
    "    # get the number of samples\n",
    "    number_of_samples = len(y)\n",
    "    # get the distinct classes and their counts\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    # calculate the probabilities, this will run for each y because counts is an array\n",
    "    probabilities = counts / number_of_samples\n",
    "    # calculate the overall entropy\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "    return entropy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:47:44.472811Z",
     "start_time": "2023-09-17T13:47:44.444385Z"
    }
   },
   "id": "54c8a034b557e38b"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(y_less_than, y_greater_than):\n",
    "    # get the number of samples\n",
    "    number_of_samples = len(y_less_than) + len(y_greater_than)\n",
    "    # calculate the probabilities\n",
    "    probabilities_less_than = len(y_less_than) / number_of_samples\n",
    "    probabilities_greater_than = len(y_greater_than) / number_of_samples\n",
    "    # calculate the overall entropy\n",
    "    overall_entropy = (\n",
    "        probabilities_less_than * calculate_entropy(y_less_than)\n",
    "        + probabilities_greater_than * calculate_entropy(y_greater_than)\n",
    "    )\n",
    "    return overall_entropy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:47:44.481135Z",
     "start_time": "2023-09-17T13:47:44.448365Z"
    }
   },
   "id": "2d8eab58429d422"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "def determine_best_split(X, y, potential_splits, impurity_measure='entropy'):\n",
    "    overall_entropy = 999\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            # split the data with current split\n",
    "            X_less_than, y_less_than, X_greater_than, y_greater_than = split_data(\n",
    "                X, y, split_column=column_index, split_value=value\n",
    "            )\n",
    "            if impurity_measure == 'entropy':\n",
    "                current_overall_entropy = calculate_overall_entropy(\n",
    "                    y_less_than, y_greater_than\n",
    "                )\n",
    "            # elif impurity_measure == 'gini':\n",
    "                # current_overall_entropy = calculate_overall_gini(\n",
    "                #    y_less_than, y_greater_than\n",
    "                #)\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "                \n",
    "    return best_split_column, best_split_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:47:44.481591Z",
     "start_time": "2023-09-17T13:47:44.467673Z"
    }
   },
   "id": "25f1496d1d0a62fd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree Algorithm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32c22e05fb613b26"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "Classification:  0\n",
      "Classification:  0\n",
      "Classification:  1\n",
      "{'1 <= 4.45': [{'3 <= 0.515': [{'0 <= 0.225': [{'3 <= 0.425': [{'1 <= 1.55': [0, {'1 <= 2.6500000000000004': [{'0 <= 0.14': [{'3 <= 0.36': [{'4 <= 10.649999999999999': [1, 0]}, 1]}, {'2 <= 3.14': [1, 0]}]}, 0]}]}, {'0 <= 0.08499999999999999': [{'3 <= 0.435': [{'2 <= 3.535': [1, 0]}, 1]}, {'1 <= 1.65': [{'2 <= 3.385': [{'2 <= 2.965': [1, {'0 <= 0.175': [0, {'0 <= 0.185': [1, {'2 <= 3.115': [{'4 <= 9.75': [0, 1]}, 0]}]}]}]}, {'3 <= 0.47': [0, 1]}]}, {'3 <= 0.46499999999999997': [{'1 <= 2.3499999999999996': [{'4 <= 11.7': [1, 0]}, {'0 <= 0.115': [1, 0]}]}, {'2 <= 3.17': [{'3 <= 0.495': [1, 0]}, {'2 <= 3.41': [1, {'4 <= 10.45': [0, 1]}]}]}]}]}]}]}, {'4 <= 10.149999999999999': [{'1 <= 1.85': [{'1 <= 1.55': [{'4 <= 9.149999999999999': [{'3 <= 0.47': [0, {'4 <= 9.05': [0, 1]}]}, 0]}, {'2 <= 3.3099999999999996': [{'4 <= 9.95': [0, {'3 <= 0.395': [0, 1]}]}, {'2 <= 3.3899999999999997': [1, {'4 <= 9.75': [{'4 <= 9.3': [0, 1]}, 0]}]}]}]}, {'3 <= 0.41000000000000003': [0, {'1 <= 2.8499999999999996': [{'2 <= 3.2': [{'0 <= 0.445': [{'0 <= 0.4': [{'3 <= 0.505': [1, {'2 <= 3.145': [0, 1]}]}, 0]}, 1]}, 1]}, {'1 <= 3.3499999999999996': [0, {'4 <= 9.05': [0, 1]}]}]}]}]}, {'3 <= 0.435': [{'2 <= 3.255': [0, {'2 <= 3.2649999999999997': [{'4 <= 11.75': [1, 0]}, 0]}]}, {'0 <= 0.255': [{'4 <= 11.1': [{'2 <= 3.465': [1, 0]}, 0]}, {'0 <= 0.295': [0, {'2 <= 3.335': [{'2 <= 3.325': [{'2 <= 2.9050000000000002': [{'4 <= 11.75': [0, 1]}, {'0 <= 0.425': [{'4 <= 11.350000000000001': [{'1 <= 2.6500000000000004': [{'4 <= 10.75': [0, {'4 <= 10.95': [{'1 <= 1.75': [{'3 <= 0.45999999999999996': [0, 1]}, 0]}, 0]}]}, {'2 <= 3.2350000000000003': [0, 1]}]}, 0]}, {'3 <= 0.49': [{'1 <= 1.625': [0, {'0 <= 0.475': [{'2 <= 3.21': [1, 0]}, 0]}]}, 1]}]}]}, {'4 <= 11.3': [0, 1]}]}, 0]}]}]}]}]}]}, {'1 <= 1.625': [{'0 <= 0.215': [{'2 <= 3.3': [{'4 <= 10.25': [{'4 <= 9.25': [{'3 <= 0.59': [0, 1]}, 1]}, 0]}, 1]}, {'1 <= 1.35': [{'3 <= 0.525': [{'4 <= 11.25': [0, 1]}, {'1 <= 1.25': [0, {'4 <= 9.4': [1, {'3 <= 0.7849999999999999': [0, {'4 <= 10.2': [0, 1]}]}]}]}]}, {'0 <= 0.365': [{'4 <= 9.4': [1, {'1 <= 1.55': [0, {'2 <= 3.67': [{'2 <= 3.27': [{'0 <= 0.355': [{'2 <= 3.16': [0, 1]}, 0]}, 0]}, 1]}]}]}, {'4 <= 11.25': [{'3 <= 0.625': [{'0 <= 0.385': [1, {'4 <= 9.45': [0, {'4 <= 9.65': [1, {'4 <= 10.3': [0, {'0 <= 0.435': [0, 1]}]}]}]}]}, {'2 <= 3.52': [{'0 <= 0.655': [{'2 <= 3.12': [{'2 <= 3.09': [1, 0]}, 1]}, 0]}, 0]}]}, {'4 <= 11.95': [{'4 <= 11.8': [{'2 <= 3.205': [1, 0]}, 1]}, 0]}]}]}]}]}, {'0 <= 0.14500000000000002': [1, {'4 <= 9.75': [{'1 <= 3.1500000000000004': [{'1 <= 1.85': [{'4 <= 9.55': [{'4 <= 9.0': [{'4 <= 8.65': [1, 0]}, {'3 <= 0.56': [{'3 <= 0.54': [1, {'4 <= 9.35': [1, 0]}]}, 1]}]}, 0]}, {'2 <= 3.185': [{'2 <= 3.175': [1, {'3 <= 0.61': [0, 1]}]}, 1]}]}, {'0 <= 0.255': [1, {'0 <= 0.49': [{'4 <= 9.649999999999999': [{'2 <= 3.2350000000000003': [{'4 <= 9.05': [0, {'0 <= 0.455': [1, 0]}]}, 0]}, 1]}, 1]}]}]}, {'0 <= 0.395': [{'2 <= 3.115': [{'3 <= 0.8400000000000001': [{'4 <= 11.05': [{'4 <= 10.35': [0, {'3 <= 0.5800000000000001': [0, {'1 <= 2.7': [1, 0]}]}]}, 0]}, 1]}, {'1 <= 3.75': [{'4 <= 13.149999999999999': [{'3 <= 0.725': [{'0 <= 0.265': [{'3 <= 0.71': [{'4 <= 9.850000000000001': [1, {'0 <= 0.245': [{'2 <= 3.415': [{'4 <= 10.95': [{'1 <= 2.45': [{'2 <= 3.385': [{'2 <= 3.205': [1, {'4 <= 10.149999999999999': [{'2 <= 3.355': [{'3 <= 0.675': [1, 0]}, 0]}, {'1 <= 2.3499999999999996': [1, {'4 <= 10.399999999999999': [1, 0]}]}]}]}, 1]}, 1]}, {'3 <= 0.55': [0, {'0 <= 0.155': [{'4 <= 12.7': [0, 1]}, 1]}]}]}, 1]}, {'4 <= 9.95': [1, {'3 <= 0.575': [0, {'1 <= 2.95': [{'1 <= 1.7999999999999998': [0, 1]}, 0]}]}]}]}]}, 0]}, {'1 <= 2.45': [{'3 <= 0.545': [{'4 <= 9.95': [1, {'4 <= 11.25': [{'4 <= 11.0': [0, 1]}, 0]}]}, {'1 <= 1.75': [{'2 <= 3.17': [1, 0]}, {'3 <= 0.695': [{'0 <= 0.275': [1, {'3 <= 0.565': [{'4 <= 10.05': [0, 1]}, {'2 <= 3.1900000000000004': [{'0 <= 0.375': [1, {'4 <= 11.1': [0, 1]}]}, {'2 <= 3.2199999999999998': [0, {'4 <= 10.149999999999999': [1, {'1 <= 2.05': [{'3 <= 0.575': [1, {'0 <= 0.38': [{'2 <= 3.25': [{'4 <= 10.5': [0, 1]}, 0]}, 1]}]}, {'0 <= 0.305': [1, {'0 <= 0.325': [0, {'3 <= 0.595': [{'3 <= 0.585': [1, 0]}, 1]}]}]}]}]}]}]}]}]}, 1]}]}]}, {'2 <= 3.3049999999999997': [1, {'3 <= 0.575': [0, {'1 <= 3.45': [{'4 <= 11.25': [1, {'0 <= 0.32': [0, 1]}]}, 0]}]}]}]}]}, {'4 <= 11.4': [1, {'3 <= 0.805': [1, {'4 <= 12.05': [{'3 <= 0.875': [{'4 <= 11.8': [1, {'4 <= 11.95': [0, 1]}]}, 0]}, 1]}]}]}]}, {'0 <= 0.22499999999999998': [0, {'4 <= 13.45': [0, 1]}]}]}, {'3 <= 0.66': [0, {'4 <= 11.15': [0, 1]}]}]}]}, {'3 <= 0.625': [{'2 <= 3.085': [{'1 <= 2.25': [0, {'1 <= 3.45': [1, 0]}]}, {'2 <= 3.3': [{'0 <= 0.715': [{'0 <= 0.525': [{'4 <= 10.25': [{'3 <= 0.565': [0, 1]}, {'3 <= 0.585': [1, {'1 <= 2.8': [{'3 <= 0.595': [0, 1]}, 0]}]}]}, 1]}, {'4 <= 12.9': [0, 1]}]}, 1]}]}, {'0 <= 0.495': [{'4 <= 10.05': [{'4 <= 9.95': [1, {'0 <= 0.48': [{'3 <= 0.65': [1, 0]}, 1]}]}, {'1 <= 1.75': [{'4 <= 11.05': [1, 0]}, {'2 <= 3.59': [{'3 <= 0.645': [{'2 <= 3.2': [{'4 <= 10.55': [1, 0]}, 1]}, 1]}, 0]}]}]}, 1]}]}]}]}]}]}]}, {'3 <= 0.635': [{'3 <= 0.485': [{'0 <= 0.065': [{'4 <= 11.65': [1, 0]}, {'0 <= 0.76': [0, 1]}]}, {'0 <= 0.20500000000000002': [{'2 <= 3.185': [{'1 <= 5.85': [{'4 <= 9.75': [{'4 <= 9.350000000000001': [0, 1]}, 0]}, 0]}, {'3 <= 0.505': [1, {'3 <= 0.515': [0, {'2 <= 3.38': [{'4 <= 9.3': [1, 0]}, {'2 <= 3.605': [1, 0]}]}]}]}]}, {'4 <= 10.850000000000001': [{'1 <= 7.95': [{'4 <= 9.649999999999999': [{'3 <= 0.555': [{'2 <= 3.3600000000000003': [0, 1]}, {'0 <= 0.28500000000000003': [0, 1]}]}, 0]}, {'2 <= 3.3200000000000003': [0, {'2 <= 3.335': [{'4 <= 9.95': [0, 1]}, 0]}]}]}, {'0 <= 0.39': [{'2 <= 3.435': [{'1 <= 8.35': [0, {'1 <= 8.75': [1, {'2 <= 3.275': [0, {'3 <= 0.53': [0, 1]}]}]}]}, {'0 <= 0.3': [1, 0]}]}, {'1 <= 7.0': [{'4 <= 11.75': [1, {'2 <= 3.185': [0, {'0 <= 0.505': [1, {'4 <= 12.4': [0, 1]}]}]}]}, {'1 <= 8.25': [0, {'1 <= 9.45': [1, 0]}]}]}]}]}]}]}, {'1 <= 6.75': [{'0 <= 0.355': [{'2 <= 3.205': [0, {'0 <= 0.29000000000000004': [{'0 <= 0.125': [1, {'2 <= 3.3099999999999996': [0, {'2 <= 3.3449999999999998': [1, 0]}]}]}, 1]}]}, {'2 <= 3.04': [0, 1]}]}, {'0 <= 0.20500000000000002': [{'2 <= 3.4699999999999998': [1, 0]}, {'0 <= 0.305': [0, {'0 <= 0.32': [1, {'2 <= 3.185': [{'3 <= 0.745': [{'0 <= 0.4': [1, 0]}, {'3 <= 0.78': [1, {'4 <= 12.65': [0, 1]}]}]}, {'3 <= 0.8': [0, {'4 <= 9.95': [0, 1]}]}]}]}]}]}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "def decision_tree_algorithm(X, y, impurity_measure='entropy'):\n",
    "    # check if the data is pure\n",
    "    if check_purity(y):\n",
    "        # classify the data as the most frequent class\n",
    "        classification = classify_data(y)\n",
    "        return classification\n",
    "    else:\n",
    "\n",
    "        # get the potential splits\n",
    "        potential_splits = get_potential_splits(X)\n",
    "        \n",
    "        # get the best split column and value\n",
    "        split_column, split_value = determine_best_split(\n",
    "            X, y, potential_splits, impurity_measure\n",
    "        )\n",
    "        # split the data according to the best split\n",
    "        X_less_than, y_less_than, X_greater_than, y_greater_than = split_data(\n",
    "            X, y, split_column, split_value\n",
    "        )\n",
    "        \n",
    "        question = \"{} <= {}\".format(split_column, split_value)\n",
    "        sub_tree = {question: []}\n",
    "        # find answers (recursion)\n",
    "        yes_answer = decision_tree_algorithm(\n",
    "            X_less_than, y_less_than, impurity_measure\n",
    "        )\n",
    "        no_answer = decision_tree_algorithm(\n",
    "            X_greater_than, y_greater_than, impurity_measure\n",
    "        )\n",
    "        # if the answers are the same, then there is no point in asking the question\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        return sub_tree\n",
    "\n",
    "print(decision_tree_algorithm(X.values, y.values))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:56:48.392850Z",
     "start_time": "2023-09-17T13:56:47.692274Z"
    }
   },
   "id": "418fa017928f6929"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "941caa7908cf031e"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "def predict(x, tree):\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:47:44.484789Z",
     "start_time": "2023-09-17T13:47:44.479733Z"
    }
   },
   "id": "e073d27a2e0c7973"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Execution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "469f23ff7491bd8c"
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "      citric acid  residual sugar    pH  sulphates  alcohol\n",
      "3034         0.38             8.1  3.30       0.54      9.8\n",
      "2576         0.23             6.2  3.34       0.43      9.6\n",
      "533          0.04             2.5  3.53       0.55      9.5\n",
      "1061         0.20             3.0  3.23       0.59      9.5\n",
      "2626         0.32            16.2  3.17       0.37     11.2\n",
      "...           ...             ...   ...        ...      ...\n",
      "1095         0.59            11.8  3.17       0.46      8.9\n",
      "1130         0.30             1.2  2.96       0.36     12.5\n",
      "1294         0.00             2.2  3.40       0.58     10.9\n",
      "860          0.14             2.4  3.66       0.65      9.8\n",
      "3174         0.39             3.2  3.37       0.71     11.5\n",
      "\n",
      "[2558 rows x 5 columns]\n",
      "3034    0\n",
      "2576    0\n",
      "533     1\n",
      "1061    1\n",
      "2626    0\n",
      "       ..\n",
      "1095    0\n",
      "1130    0\n",
      "1294    1\n",
      "860     1\n",
      "3174    1\n",
      "Name: type, Length: 2558, dtype: int64\n",
      "\n",
      "Validation data:\n",
      "      citric acid  residual sugar    pH  sulphates  alcohol\n",
      "2440         0.59             2.2  3.20       0.78      9.6\n",
      "354          0.27             4.7  3.16       0.42     12.5\n",
      "601          0.00             1.2  3.32       0.51      9.8\n",
      "1159         0.43             2.2  3.16       0.67     10.8\n",
      "1465         0.02             2.1  3.38       0.69      9.5\n",
      "...           ...             ...   ...        ...      ...\n",
      "561          0.07             1.4  3.32       0.81      9.6\n",
      "282          0.49             2.4  3.14       0.61     10.4\n",
      "2118         0.32            12.9  3.30       0.56     11.5\n",
      "2643         0.21             1.5  3.16       0.54      9.8\n",
      "801          0.24             1.7  3.29       0.67     10.0\n",
      "\n",
      "[640 rows x 5 columns]\n",
      "2440    1\n",
      "354     0\n",
      "601     1\n",
      "1159    1\n",
      "1465    1\n",
      "       ..\n",
      "561     1\n",
      "282     1\n",
      "2118    1\n",
      "2643    1\n",
      "801     1\n",
      "Name: type, Length: 640, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = split_dataset(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training data:\")\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "\n",
    "print(\"\\nValidation data:\")\n",
    "print(X_val)\n",
    "print(y_val)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:47:44.519654Z",
     "start_time": "2023-09-17T13:47:44.487219Z"
    }
   },
   "id": "20ee0c755692f9fa"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "learn(X, y, 'entropy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:47:44.520153Z",
     "start_time": "2023-09-17T13:47:44.495974Z"
    }
   },
   "id": "10fe4b1db369b66e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
